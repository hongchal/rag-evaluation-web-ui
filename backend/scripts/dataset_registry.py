#!/usr/bin/env python3
"""
ë°ì´í„°ì…‹ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ê´€ë¦¬ ìŠ¤í¬ë¦½íŠ¸

ë‹¤ìš´ë¡œë“œí•œ ë°ì´í„°ì…‹ì„ ë°ì´í„°ë² ì´ìŠ¤ì— ë“±ë¡í•˜ê³  ê´€ë¦¬í•©ë‹ˆë‹¤.

Usage:
    # íŠ¹ì • ë°ì´í„°ì…‹ ë“±ë¡
    python backend/scripts/dataset_registry.py register backend/datasets/frames_eval.json
    
    # ëª¨ë“  ë°ì´í„°ì…‹ ìë™ ë“±ë¡
    python backend/scripts/dataset_registry.py auto-register
    
    # ë“±ë¡ëœ ë°ì´í„°ì…‹ ëª©ë¡ í™•ì¸
    python backend/scripts/dataset_registry.py list
"""

import argparse
import json
import os
import sys
from pathlib import Path
from typing import List, Dict, Any, Optional

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python pathì— ì¶”ê°€
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root / "backend"))

try:
    from sqlalchemy import create_engine
    from sqlalchemy.orm import sessionmaker
    from app.core.config import settings
    from app.models.evaluation_dataset import EvaluationDataset
    from app.models.evaluation_document import EvaluationDocument
    from app.models.evaluation_query import EvaluationQuery
    from app.core.database import Base
except ImportError as e:
    print(f"âŒ í•„ìˆ˜ ëª¨ë“ˆì„ importí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
    print("   backend ë””ë ‰í† ë¦¬ê°€ Python pathì— ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
    sys.exit(1)


class DatasetRegistry:
    """ë°ì´í„°ì…‹ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ê´€ë¦¬ì"""
    
    def __init__(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì´ˆê¸°í™”"""
        try:
            # DATABASE_URL í™˜ê²½ë³€ìˆ˜ë¥¼ ìš°ì„ ì ìœ¼ë¡œ ì‚¬ìš© (ì„œë¸Œí”„ë¡œì„¸ìŠ¤ ì‹¤í–‰ ì‹œ)
            database_url = os.environ.get("DATABASE_URL", settings.database_url)
            
            # ë°ì´í„°ë² ì´ìŠ¤ ì—”ì§„ ìƒì„±
            self.engine = create_engine(
                database_url,
                echo=False,
                pool_pre_ping=True
            )
            
            # í…Œì´ë¸” ìƒì„±
            Base.metadata.create_all(bind=self.engine)
            
            # ì„¸ì…˜ íŒ©í† ë¦¬
            SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=self.engine)
            self.session = SessionLocal()
            
            print("âœ… ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì™„ë£Œ")
            
        except Exception as e:
            print(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨: {e}")
            sys.exit(1)
    
    def __del__(self):
        """ì„¸ì…˜ ì •ë¦¬"""
        if hasattr(self, 'session'):
            self.session.close()
    
    def register_dataset(self, dataset_file: str) -> bool:
        """ë°ì´í„°ì…‹ì„ ë°ì´í„°ë² ì´ìŠ¤ì— ë“±ë¡"""
        
        dataset_path = Path(dataset_file)
        
        if not dataset_path.exists():
            print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {dataset_file}")
            return False
        
        print(f"\nğŸ“ ë°ì´í„°ì…‹ ë“±ë¡: {dataset_path.name}")
        
        try:
            # JSON íŒŒì¼ ë¡œë“œ
            with open(dataset_path, "r", encoding="utf-8") as f:
                data = json.load(f)
            
            # ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
            name = data.get("name", dataset_path.stem)
            description = data.get("description", "")
            documents = data.get("documents", [])
            queries = data.get("queries", [])
            metadata = data.get("metadata", {})
            
            print(f"   ì´ë¦„: {name}")
            print(f"   ë¬¸ì„œ: {len(documents)}ê°œ")
            print(f"   ì¿¼ë¦¬: {len(queries)}ê°œ")
            
            # ì´ë¯¸ ë“±ë¡ëœ ë°ì´í„°ì…‹ì¸ì§€ í™•ì¸
            existing = self.session.query(EvaluationDataset).filter_by(name=name).first()
            
            if existing:
                print(f"   âš ï¸  ì´ë¯¸ ë“±ë¡ëœ ë°ì´í„°ì…‹ì…ë‹ˆë‹¤ (ID: {existing.id})")
                print(f"   ê¸°ì¡´ ë°ì´í„°ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤...")
                
                # ê¸°ì¡´ ë¬¸ì„œì™€ ì¿¼ë¦¬ ì‚­ì œ
                self.session.query(EvaluationDocument).filter_by(dataset_id=existing.id).delete()
                self.session.query(EvaluationQuery).filter_by(dataset_id=existing.id).delete()
                
                # ë°ì´í„°ì…‹ ì—…ë°ì´íŠ¸
                existing.description = description
                existing.dataset_uri = str(dataset_path.absolute())
                existing.num_queries = len(queries)
                existing.num_documents = len(documents)
                dataset_obj = existing
            else:
                # ìƒˆ ë°ì´í„°ì…‹ ìƒì„±
                dataset_obj = EvaluationDataset(
                    name=name,
                    description=description,
                    dataset_uri=str(dataset_path.absolute()),
                    num_queries=len(queries),
                    num_documents=len(documents)
                )
                self.session.add(dataset_obj)
                self.session.flush()  # ID ìƒì„±
            
            # ë¬¸ì„œ ì¶”ê°€
            print(f"   ğŸ“„ ë¬¸ì„œ ë“±ë¡ ì¤‘...")
            for doc_data in documents:
                doc = EvaluationDocument(
                    dataset_id=dataset_obj.id,
                    doc_id=doc_data["id"],
                    content=doc_data["content"],
                    title=doc_data.get("title", ""),
                    metadata=doc_data.get("metadata", {})
                )
                self.session.add(doc)
            
            # ì¿¼ë¦¬ ì¶”ê°€
            print(f"   â“ ì¿¼ë¦¬ ë“±ë¡ ì¤‘...")
            for query_data in queries:
                query = EvaluationQuery(
                    dataset_id=dataset_obj.id,
                    query=query_data["query"],
                    relevant_doc_ids=query_data.get("relevant_doc_ids", []),
                    expected_answer=query_data.get("expected_answer", ""),
                    difficulty=query_data.get("difficulty", "medium"),
                    query_type=query_data.get("query_type", "unknown"),
                    metadata=query_data.get("metadata", {})
                )
                self.session.add(query)
            
            # ì»¤ë°‹
            self.session.commit()
            
            print(f"   âœ… ë“±ë¡ ì™„ë£Œ! (Dataset ID: {dataset_obj.id})")
            return True
            
        except json.JSONDecodeError as e:
            print(f"âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            return False
        except Exception as e:
            print(f"âŒ ë“±ë¡ ì‹¤íŒ¨: {e}")
            self.session.rollback()
            return False
    
    def auto_register(self, dataset_dir: str = "backend/datasets") -> List[str]:
        """ë””ë ‰í† ë¦¬ì˜ ëª¨ë“  JSON íŒŒì¼ì„ ìë™ ë“±ë¡"""
        
        dataset_path = Path(dataset_dir)
        
        if not dataset_path.exists():
            print(f"âŒ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {dataset_dir}")
            return []
        
        print(f"\nğŸ” ë°ì´í„°ì…‹ ë””ë ‰í† ë¦¬ ìŠ¤ìº”: {dataset_dir}")
        
        # JSON íŒŒì¼ ì°¾ê¸°
        json_files = list(dataset_path.glob("*_eval.json"))
        
        if not json_files:
            print(f"   âš ï¸  ë“±ë¡í•  ë°ì´í„°ì…‹ì´ ì—†ìŠµë‹ˆë‹¤ (*_eval.json)")
            return []
        
        print(f"   ë°œê²¬í•œ ë°ì´í„°ì…‹: {len(json_files)}ê°œ")
        
        registered = []
        
        for json_file in json_files:
            if self.register_dataset(str(json_file)):
                registered.append(str(json_file))
        
        print(f"\nâœ… ìë™ ë“±ë¡ ì™„ë£Œ: {len(registered)}/{len(json_files)}")
        
        return registered
    
    def list_datasets(self):
        """ë“±ë¡ëœ ë°ì´í„°ì…‹ ëª©ë¡ ì¶œë ¥"""
        
        print("\nğŸ“š ë“±ë¡ëœ ë°ì´í„°ì…‹ ëª©ë¡:\n")
        
        try:
            datasets = self.session.query(EvaluationDataset).all()
            
            if not datasets:
                print("   ë“±ë¡ëœ ë°ì´í„°ì…‹ì´ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            for ds in datasets:
                # ë¬¸ì„œì™€ ì¿¼ë¦¬ ê°œìˆ˜ ê³„ì‚°
                doc_count = self.session.query(EvaluationDocument).filter_by(dataset_id=ds.id).count()
                query_count = self.session.query(EvaluationQuery).filter_by(dataset_id=ds.id).count()
                
                print(f"ğŸ“¦ {ds.name} (ID: {ds.id})")
                print(f"   ì„¤ëª…: {ds.description}")
                print(f"   ë¬¸ì„œ: {doc_count}ê°œ")
                print(f"   ì¿¼ë¦¬: {query_count}ê°œ")
                print(f"   ìƒì„±ì¼: {ds.created_at}")
                print()
            
            print(f"ì´ {len(datasets)}ê°œ ë°ì´í„°ì…‹ ë“±ë¡ë¨")
            
        except Exception as e:
            print(f"âŒ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
    
    def delete_dataset(self, dataset_id: int) -> bool:
        """ë°ì´í„°ì…‹ ì‚­ì œ"""
        
        print(f"\nğŸ—‘ï¸  ë°ì´í„°ì…‹ ì‚­ì œ: ID {dataset_id}")
        
        try:
            # ë°ì´í„°ì…‹ ì°¾ê¸°
            dataset = self.session.query(EvaluationDataset).filter_by(id=dataset_id).first()
            
            if not dataset:
                print(f"âŒ ë°ì´í„°ì…‹ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: ID {dataset_id}")
                return False
            
            print(f"   ì´ë¦„: {dataset.name}")
            
            # ê´€ë ¨ ë¬¸ì„œì™€ ì¿¼ë¦¬ë„ í•¨ê»˜ ì‚­ì œ (CASCADE)
            self.session.delete(dataset)
            self.session.commit()
            
            print(f"   âœ… ì‚­ì œ ì™„ë£Œ!")
            return True
            
        except Exception as e:
            print(f"âŒ ì‚­ì œ ì‹¤íŒ¨: {e}")
            self.session.rollback()
            return False


def main():
    parser = argparse.ArgumentParser(
        description="ë°ì´í„°ì…‹ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ê´€ë¦¬",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì˜ˆì œ:
  # íŠ¹ì • ë°ì´í„°ì…‹ ë“±ë¡
  python backend/scripts/dataset_registry.py register backend/datasets/frames_eval.json
  
  # ëª¨ë“  ë°ì´í„°ì…‹ ìë™ ë“±ë¡
  python backend/scripts/dataset_registry.py auto-register
  
  # ë‹¤ë¥¸ ë””ë ‰í† ë¦¬ì˜ ë°ì´í„°ì…‹ ìë™ ë“±ë¡
  python backend/scripts/dataset_registry.py auto-register --dir /path/to/datasets
  
  # ë“±ë¡ëœ ë°ì´í„°ì…‹ ëª©ë¡ í™•ì¸
  python backend/scripts/dataset_registry.py list
  
  # ë°ì´í„°ì…‹ ì‚­ì œ
  python backend/scripts/dataset_registry.py delete --id 1
        """
    )
    
    subparsers = parser.add_subparsers(dest="command", help="ëª…ë ¹ì–´")
    
    # ë“±ë¡ ëª…ë ¹
    register_parser = subparsers.add_parser("register", help="ë°ì´í„°ì…‹ ë“±ë¡")
    register_parser.add_argument("dataset_file", help="ë“±ë¡í•  ë°ì´í„°ì…‹ JSON íŒŒì¼")
    
    # ìë™ ë“±ë¡ ëª…ë ¹
    auto_parser = subparsers.add_parser("auto-register", help="ë””ë ‰í† ë¦¬ì˜ ëª¨ë“  ë°ì´í„°ì…‹ ìë™ ë“±ë¡")
    auto_parser.add_argument("--dir", default="backend/datasets", help="ë°ì´í„°ì…‹ ë””ë ‰í† ë¦¬")
    
    # ëª©ë¡ ëª…ë ¹
    list_parser = subparsers.add_parser("list", help="ë“±ë¡ëœ ë°ì´í„°ì…‹ ëª©ë¡")
    
    # ì‚­ì œ ëª…ë ¹
    delete_parser = subparsers.add_parser("delete", help="ë°ì´í„°ì…‹ ì‚­ì œ")
    delete_parser.add_argument("--id", type=int, required=True, help="ì‚­ì œí•  ë°ì´í„°ì…‹ ID")
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        sys.exit(1)
    
    # ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì´ˆê¸°í™”
    registry = DatasetRegistry()
    
    # ëª…ë ¹ ì‹¤í–‰
    if args.command == "register":
        registry.register_dataset(args.dataset_file)
    
    elif args.command == "auto-register":
        registry.auto_register(args.dir)
    
    elif args.command == "list":
        registry.list_datasets()
    
    elif args.command == "delete":
        registry.delete_dataset(args.id)


if __name__ == "__main__":
    main()

