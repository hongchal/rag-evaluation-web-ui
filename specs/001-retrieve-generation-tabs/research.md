# Research & Technical Decisions

**Feature**: Retrieve & Generation Tabs Separation
**Date**: 2025-10-28
**Status**: Complete

## Overview

ì´ ë¬¸ì„œëŠ” Retrieve/Generation íƒ­ ë¶„ë¦¬ ê¸°ëŠ¥ êµ¬í˜„ì— í•„ìš”í•œ ê¸°ìˆ ì  ì˜ì‚¬ê²°ì •ê³¼ ê·¸ ê·¼ê±°ë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤. ê° ê²°ì •ì€ ê¸°ì¡´ ì½”ë“œë² ì´ìŠ¤ ë¶„ì„, ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤ ì¡°ì‚¬, ê·¸ë¦¬ê³  í”„ë¡œì íŠ¸ ìš”êµ¬ì‚¬í•­ì„ ê¸°ë°˜ìœ¼ë¡œ í•©ë‹ˆë‹¤.

## 1. Chat Context Management

### Decision: In-Memory Session State (Frontend)

ì±„íŒ… ì„¸ì…˜ì˜ ëŒ€í™” ë§¥ë½ì„ ë¸Œë¼ìš°ì € ë©”ëª¨ë¦¬(React state)ì—ì„œ ê´€ë¦¬í•©ë‹ˆë‹¤.

### Rationale

**ì¥ì **:
- êµ¬í˜„ ë‹¨ìˆœì„±: ë³„ë„ ì„¸ì…˜ ì €ì¥ì†Œ ë¶ˆí•„ìš”
- ë¹ ë¥¸ ì‘ë‹µ: ë„¤íŠ¸ì›Œí¬ ì™•ë³µ ì—†ìŒ
- ì‚¬ìš©ì í”„ë¼ì´ë²„ì‹œ: ì„œë²„ì— ëŒ€í™” ë‚´ìš© ì €ì¥ ì•ˆ í•¨
- ì´ˆê¸° êµ¬í˜„ ë¹„ìš© ìµœì†Œí™”

**ë‹¨ì **:
- ìƒˆë¡œê³ ì¹¨ ì‹œ ì„¸ì…˜ ì†ì‹¤
- ë¸Œë¼ìš°ì € ê°„ ì„¸ì…˜ ê³µìœ  ë¶ˆê°€
- ë©”ëª¨ë¦¬ ì œí•œ

**ê·¼ê±°**:
1. ëª…ì„¸ì„œì˜ Assumptions: "ì±„íŒ… ì„¸ì…˜ì˜ ëŒ€í™” ë§¥ë½ì€ ë¸Œë¼ìš°ì € ì„¸ì…˜ ë‚´ì—ì„œë§Œ ìœ ì§€ë˜ë©°, ìƒˆë¡œê³ ì¹¨ ì‹œ ì´ˆê¸°í™”ë©ë‹ˆë‹¤"
2. Out of Scope: "ì±„íŒ… ì„¸ì…˜ì˜ ì˜êµ¬ ì €ì¥ ë° íˆìŠ¤í† ë¦¬ ê´€ë¦¬"
3. ì—°êµ¬ ëª©ì : ì‚¬ìš©ìëŠ” RAG íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ê°€ ì£¼ ëª©ì ì´ë¯€ë¡œ ì˜êµ¬ ì €ì¥ í•„ìš”ì„± ë‚®ìŒ

### Alternatives Considered

1. **Backend Session Storage (Redis/PostgreSQL)**
   - ì¥ì : ì˜êµ¬ ì €ì¥, ë¸Œë¼ìš°ì € ê°„ ê³µìœ 
   - ë‹¨ì : ë³µì¡ë„ ì¦ê°€, ì¶”ê°€ ì¸í”„ë¼ í•„ìš”
   - ê±°ë¶€ ì´ìœ : í˜„ì¬ ë²”ìœ„ì—ì„œ ê³¼ë„í•œ ì„¤ê³„

2. **Local Storage**
   - ì¥ì : ìƒˆë¡œê³ ì¹¨ í›„ì—ë„ ìœ ì§€
   - ë‹¨ì : ë³´ì•ˆ ì´ìŠˆ (API í‚¤ ì €ì¥), ìš©ëŸ‰ ì œí•œ (5-10MB)
   - ê±°ë¶€ ì´ìœ : API í‚¤ ë³´ì•ˆ ìœ„í—˜, ëª…ì„¸ì„œ ê°€ì •ê³¼ ë¶ˆì¼ì¹˜

### Implementation Details

```typescript
// Frontend State Structure
interface ChatSession {
  id: string;  // UUID v4
  pipelineId: number;
  modelConfig: ModelConfig;
  messages: Message[];
  createdAt: Date;
}

interface Message {
  id: string;  // UUID v4
  role: 'user' | 'assistant';
  content: string;
  sources?: RetrievedChunk[];
  timestamp: Date;
}
```

**Context Management Strategy**:
- ìµœëŒ€ ë©”ì‹œì§€ ìˆ˜: 50ê°œ (ì´ˆê³¼ ì‹œ ìë™ ì •ë¦¬)
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì •: ~1MB per session (í…ìŠ¤íŠ¸ + ë©”íƒ€ë°ì´í„°)
- 10ê°œ ë™ì‹œ ì„¸ì…˜ = ~10MB (ì„±ëŠ¥ ëª©í‘œ ì¶©ì¡±)

---

## 2. Generation Model Abstraction

### Decision: Strategy Pattern with Abstract Base Class

Claudeì™€ vLLMì„ í†µí•©í•˜ê¸° ìœ„í•´ Abstract Generator ì¸í„°í˜ì´ìŠ¤ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.

### Rationale

**íŒ¨í„´ ì„ íƒ ì´ìœ **:
- í™•ì¥ì„±: í–¥í›„ OpenAI, Gemini ë“± ì¶”ê°€ ëª¨ë¸ ì§€ì› ìš©ì´
- í…ŒìŠ¤íŠ¸ ìš©ì´ì„±: Mock Generatorë¡œ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥
- ì˜ì¡´ì„± ì—­ì „: Query Serviceê°€ êµ¬ì²´ì ì¸ êµ¬í˜„ì— ì˜ì¡´í•˜ì§€ ì•ŠìŒ

**ê·¼ê±°**:
1. ëª…ì„¸ì„œì˜ Out of Scopeì— "OpenAI, Gemini ë“± ë‹¤ë¥¸ ìƒì„± ëª¨ë¸ ì œê³µì ì§€ì›"ì´ ëª…ì‹œë˜ì–´ ìˆì–´ í–¥í›„ í™•ì¥ ê°€ëŠ¥ì„± ì¡´ì¬
2. Claudeì™€ vLLMì˜ API ì¸í„°í˜ì´ìŠ¤ê°€ ë‹¤ë¥´ë¯€ë¡œ ì¶”ìƒí™” í•„ìš”
3. ê¸°ì¡´ ì½”ë“œë² ì´ìŠ¤ì˜ Embedder/Reranker íŒ¨í„´ê³¼ ì¼ê´€ì„± ìœ ì§€

### Alternatives Considered

1. **Adapter Pattern**
   - ì¥ì : ê¸°ì¡´ ì¸í„°í˜ì´ìŠ¤ ì¬ì‚¬ìš©
   - ë‹¨ì : Claude/vLLMì´ í‘œì¤€ ì¸í„°í˜ì´ìŠ¤ê°€ ì—†ìŒ
   - ê±°ë¶€ ì´ìœ : ìš°ë¦¬ê°€ ì¸í„°í˜ì´ìŠ¤ë¥¼ ì •ì˜í•´ì•¼ í•˜ë¯€ë¡œ Strategyê°€ ë” ì í•©

2. **Direct Implementation (No Abstraction)**
   - ì¥ì : ë‹¨ìˆœí•¨
   - ë‹¨ì : ì½”ë“œ ì¤‘ë³µ, í™•ì¥ ì–´ë ¤ì›€
   - ê±°ë¶€ ì´ìœ : ì´ë¯¸ 2ê°œ ëª¨ë¸ì´ë¯€ë¡œ ì¶”ìƒí™” ì •ë‹¹í™”ë¨

### Implementation Details

```python
# backend/app/services/generation/base.py
from abc import ABC, abstractmethod
from typing import List, Dict, Any
from dataclasses import dataclass

@dataclass
class GenerationConfig:
    """Configuration for text generation"""
    temperature: float = 0.7
    max_tokens: int = 1000
    top_p: float = 0.9
    stop_sequences: List[str] = None

@dataclass
class GenerationResult:
    """Result of text generation"""
    answer: str
    tokens_used: int
    generation_time: float
    model_name: str

class AbstractGenerator(ABC):
    """Abstract base class for text generation models"""
    
    @abstractmethod
    def generate(
        self,
        query: str,
        context: str,
        config: GenerationConfig = None,
    ) -> GenerationResult:
        """
        Generate answer based on query and context.
        
        Args:
            query: User question
            context: Retrieved chunks formatted as context
            config: Generation parameters
            
        Returns:
            GenerationResult with answer and metadata
        """
        pass
    
    @abstractmethod
    def is_available(self) -> bool:
        """Check if the generator is available (API key valid, server reachable, etc.)"""
        pass
```

**Factory Pattern for Model Selection**:

```python
# backend/app/services/generation/factory.py
from app.services.generation.base import AbstractGenerator
from app.services.generation.claude import ClaudeGenerator
from app.services.generation.vllm_http import VLLMHttpGenerator

class GeneratorFactory:
    """Factory for creating generation models"""
    
    @staticmethod
    def create(model_type: str, **kwargs) -> AbstractGenerator:
        if model_type == "claude":
            return ClaudeGenerator(
                api_key=kwargs.get("api_key"),
                model_name=kwargs.get("model_name", "claude-3-sonnet-20240229")
            )
        elif model_type == "vllm":
            return VLLMHttpGenerator(
                endpoint=kwargs.get("endpoint"),
                model_name=kwargs.get("model_name")
            )
        else:
            raise ValueError(f"Unknown model type: {model_type}")
```

---

## 3. Prompt Engineering

### Decision: System Prompt + User Prompt with Context Injection

RAG ì»¨í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•œ êµ¬ì¡°í™”ëœ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

### Rationale

**í”„ë¡¬í”„íŠ¸ êµ¬ì¡°**:
- System Prompt: ì—­í•  ì •ì˜ ë° ì§€ì¹¨
- Context: ê²€ìƒ‰ëœ ë¬¸ì„œë“¤
- User Question: ì‹¤ì œ ì§ˆë¬¸

**ê·¼ê±°**:
1. Claude/vLLM ëª¨ë‘ System/User ì—­í•  êµ¬ë¶„ ì§€ì›
2. ëª…í™•í•œ ì»¨í…ìŠ¤íŠ¸ êµ¬ë¶„ìœ¼ë¡œ hallucination ê°ì†Œ
3. ì¶œì²˜ ëª…ì‹œ ìš”êµ¬ë¡œ ë‹µë³€ ê²€ì¦ ê°€ëŠ¥ì„± í–¥ìƒ

### Implementation Details

```python
DEFAULT_SYSTEM_PROMPT = """You are a helpful AI assistant that answers questions based on the provided context.

Instructions:
- Answer the question using ONLY the information from the provided context
- If the context doesn't contain enough information to answer, say "I cannot find enough information in the provided documents to answer this question."
- Cite the source document numbers when you use information from them
- Be concise but complete in your answers
- Use Korean if the question is in Korean, English if in English
"""

def format_prompt(query: str, chunks: List[Dict[str, Any]]) -> str:
    """Format RAG prompt with context and query"""
    
    # Format context from retrieved chunks
    context_parts = []
    for i, chunk in enumerate(chunks, 1):
        context_parts.append(f"[Document {i}]")
        context_parts.append(chunk["content"])
        context_parts.append("")  # blank line
    
    context = "\n".join(context_parts)
    
    # Build user prompt
    user_prompt = f"""Context:
{context}

Question: {query}

Answer:"""
    
    return user_prompt
```

**Context Length Management**:
- ìµœëŒ€ ì»¨í…ìŠ¤íŠ¸ í† í°: 4000 tokens (Claude 100K ì¤‘ ì—¬ìœ  ìˆê²Œ)
- top_k ê¸°ë³¸ê°’: 5 (ì²­í¬ë‹¹ ~500 tokens ê°€ì • â†’ ì´ 2500 tokens + ì—¬ìœ )
- í† í° ì´ˆê³¼ ì‹œ: ì²­í¬ ìë¥´ê¸° ë˜ëŠ” ê°œìˆ˜ ì¤„ì´ê¸°

### Alternatives Considered

1. **Few-Shot Prompting**
   - ì¥ì : ë” ë‚˜ì€ ë‹µë³€ í’ˆì§ˆ
   - ë‹¨ì : ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ì¦ê°€
   - ê±°ë¶€ ì´ìœ : ëª…ì„¸ì„œì—ì„œ í”„ë¡¬í”„íŠ¸ ì»¤ìŠ¤í„°ë§ˆì´ì§•ì´ Out of Scope

2. **Chain-of-Thought Prompting**
   - ì¥ì : ì¶”ë¡  ê³¼ì • í‘œì‹œ
   - ë‹¨ì : ë‹µë³€ ê¸¸ì´ ì¦ê°€, ëŠë¦° ì‘ë‹µ
   - ê±°ë¶€ ì´ìœ : 30ì´ˆ ì„±ëŠ¥ ëª©í‘œ ì¶©ì¡± ì–´ë ¤ì›€

---

## 4. Error Handling Strategy

### Decision: Exponential Backoff with Circuit Breaker Pattern

API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„ ë¡œì§ê³¼ ì—°ì† ì‹¤íŒ¨ ì‹œ ì„œí‚· ë¸Œë ˆì´ì»¤ë¥¼ ì ìš©í•©ë‹ˆë‹¤.

### Rationale

**ì „ëµ ì„ íƒ ì´ìœ **:
- Claude API rate limit: 429 ì—ëŸ¬ ì‹œ ì¬ì‹œë„ í•„ìš”
- vLLM server down: ë¹ ë¥¸ ì‹¤íŒ¨ë¡œ ì‚¬ìš©ì ê²½í—˜ ê°œì„ 
- ë¶€ë¶„ì  ì¥ì•  ëŒ€ì‘: Circuit Breakerë¡œ cascading failure ë°©ì§€

**ê·¼ê±°**:
1. ëª…ì„¸ì„œ Edge Cases: "API í• ë‹¹ëŸ‰ ì´ˆê³¼", "vLLM ì„œë²„ ì—°ê²° ì‹¤íŒ¨"
2. Success Criteria: "5ë²ˆì˜ ì—°ì†ì ì¸ ëŒ€í™”ë¥¼ ì˜¤ë¥˜ ì—†ì´ ì§„í–‰" â†’ ë†’ì€ ê°€ìš©ì„± í•„ìš”
3. ì™¸ë¶€ ì˜ì¡´ì„±: Claude/vLLM ëª¨ë‘ ë„¤íŠ¸ì›Œí¬ ì˜ì¡´ì 

### Implementation Details

```python
# backend/app/services/generation/retry.py
import asyncio
from typing import Callable, TypeVar, Any
import structlog

logger = structlog.get_logger(__name__)
T = TypeVar('T')

class RetryConfig:
    """Configuration for retry logic"""
    max_attempts: int = 3
    base_delay: float = 1.0  # seconds
    max_delay: float = 10.0  # seconds
    exponential_base: float = 2.0

async def retry_with_backoff(
    func: Callable[..., T],
    config: RetryConfig = None,
    retryable_errors: tuple = (TimeoutError, ConnectionError),
) -> T:
    """
    Retry function with exponential backoff.
    
    Args:
        func: Async function to retry
        config: Retry configuration
        retryable_errors: Tuple of exceptions to retry on
    
    Returns:
        Function result
        
    Raises:
        Last exception if all retries exhausted
    """
    config = config or RetryConfig()
    
    for attempt in range(config.max_attempts):
        try:
            return await func()
        except retryable_errors as e:
            if attempt == config.max_attempts - 1:
                logger.error("retry_exhausted", attempts=config.max_attempts, error=str(e))
                raise
            
            delay = min(
                config.base_delay * (config.exponential_base ** attempt),
                config.max_delay
            )
            logger.warning("retry_attempt", attempt=attempt+1, delay=delay, error=str(e))
            await asyncio.sleep(delay)

# Circuit Breaker (Simple Implementation)
class CircuitBreaker:
    """Simple circuit breaker for external service calls"""
    
    def __init__(self, failure_threshold: int = 5, timeout: int = 60):
        self.failure_threshold = failure_threshold
        self.timeout = timeout  # seconds
        self.failures = 0
        self.last_failure_time = None
        self.is_open = False
    
    def call_succeeded(self):
        """Record successful call"""
        self.failures = 0
        self.is_open = False
    
    def call_failed(self):
        """Record failed call"""
        self.failures += 1
        self.last_failure_time = asyncio.get_event_loop().time()
        
        if self.failures >= self.failure_threshold:
            self.is_open = True
            logger.error("circuit_breaker_opened", failures=self.failures)
    
    def can_attempt(self) -> bool:
        """Check if call should be attempted"""
        if not self.is_open:
            return True
        
        # Check if timeout has passed
        if self.last_failure_time:
            elapsed = asyncio.get_event_loop().time() - self.last_failure_time
            if elapsed >= self.timeout:
                logger.info("circuit_breaker_half_open", elapsed=elapsed)
                self.is_open = False
                self.failures = 0
                return True
        
        return False
```

**Error Classification**:

| Error Type | Retry | User Message |
|------------|-------|--------------|
| Claude 429 (Rate Limit) | Yes (3x) | "API rate limit reached. Please wait a moment." |
| Claude 401 (Invalid Key) | No | "Invalid API key. Please check your settings." |
| vLLM Connection Error | Yes (2x) | "Cannot connect to model server. Please check the endpoint." |
| vLLM Timeout | Yes (2x) | "Model server is taking too long. Please try again." |
| Context Too Long | No | "Query context is too long. Please use fewer documents." |
| Unknown Error | No | "An unexpected error occurred. Please try again." |

### Alternatives Considered

1. **No Retry (Fail Fast)**
   - ì¥ì : ë‹¨ìˆœí•¨, ë¹ ë¥¸ í”¼ë“œë°±
   - ë‹¨ì : ì¼ì‹œì  ì˜¤ë¥˜ì—ë„ ì‹¤íŒ¨
   - ê±°ë¶€ ì´ìœ : ë„¤íŠ¸ì›Œí¬ ë¶ˆì•ˆì •ì„± ëŒ€ì‘ ë¶ˆê°€

2. **Infinite Retry**
   - ì¥ì : ê²°êµ­ ì„±ê³µ
   - ë‹¨ì : ì‚¬ìš©ì ëŒ€ê¸° ì‹œê°„ ì¦ê°€
   - ê±°ë¶€ ì´ìœ : 30ì´ˆ ì„±ëŠ¥ ëª©í‘œ ìœ„ë°°

---

## 5. Dataset-Pipeline Relationship

### Decision: Existing Foreign Key Relationship

Pipeline ëª¨ë¸ì˜ ê¸°ì¡´ `dataset_id` foreign keyë¥¼ í™œìš©í•©ë‹ˆë‹¤.

### Rationale

**ê¸°ì¡´ ë°ì´í„° ëª¨ë¸**:
```python
# backend/app/models/pipeline.py
class Pipeline(Base):
    ...
    dataset_id = Column(Integer, ForeignKey("evaluation_datasets.id"), nullable=True)
    dataset = relationship("EvaluationDataset", backref="pipelines")
```

**ê·¼ê±°**:
1. ì´ë¯¸ êµ¬í˜„ëœ ê´€ê³„: Pipelineê³¼ EvaluationDataset ê°„ì˜ many-to-one ê´€ê³„ ì¡´ì¬
2. ë‹¨ìˆœí•œ ì¿¼ë¦¬: `db.query(Pipeline).filter(Pipeline.dataset_id == dataset_id)`
3. ì¼ê´€ì„±: ê¸°ì¡´ ì•„í‚¤í…ì²˜ì™€ ì¼ì¹˜

### Implementation Details

```python
# backend/app/api/routes/pipelines.py
from fastapi import APIRouter, Query

@router.get("/", response_model=List[PipelineResponse])
def list_pipelines(
    dataset_id: Optional[int] = Query(None, description="Filter by evaluation dataset ID"),
    db: Session = Depends(get_db),
):
    """
    List all pipelines, optionally filtered by dataset.
    
    Query Parameters:
        dataset_id: If provided, only return pipelines using this dataset
    """
    query = db.query(Pipeline)
    
    if dataset_id is not None:
        query = query.filter(Pipeline.dataset_id == dataset_id)
    
    pipelines = query.order_by(Pipeline.created_at.desc()).all()
    
    return [
        PipelineResponse(
            id=p.id,
            name=p.name,
            pipeline_type=p.pipeline_type,
            dataset=DatasetSummary(**p.dataset.__dict__) if p.dataset else None,
            ...
        )
        for p in pipelines
    ]
```

**Frontend Implementation**:
```typescript
// frontend/src/routes/evaluate.tsx
const [selectedDatasetId, setSelectedDatasetId] = useState<number | null>(null);
const [pipelines, setPipelines] = useState<Pipeline[]>([]);

useEffect(() => {
  loadPipelines(selectedDatasetId);
}, [selectedDatasetId]);

const loadPipelines = async (datasetId: number | null) => {
  const params = datasetId ? { dataset_id: datasetId } : {};
  const items = await api.listPipelines(params);
  setPipelines(items);
};
```

### Alternatives Considered

1. **Tags or Categories**
   - ì¥ì : ë” ìœ ì—°í•œ ë¶„ë¥˜
   - ë‹¨ì : ê¸°ì¡´ ëª¨ë¸ ë³€ê²½ í•„ìš”
   - ê±°ë¶€ ì´ìœ : Dataset ê´€ê³„ë¡œ ì¶©ë¶„, ë¶ˆí•„ìš”í•œ ë³µì¡ë„

2. **Join Table (Many-to-Many)**
   - ì¥ì : íŒŒì´í”„ë¼ì¸ì´ ì—¬ëŸ¬ ë°ì´í„°ì…‹ ì°¸ì¡° ê°€ëŠ¥
   - ë‹¨ì : í˜„ì¬ ìš”êµ¬ì‚¬í•­ì— ê³¼ë„í•¨
   - ê±°ë¶€ ì´ìœ : ëª…ì„¸ì„œì—ì„œ 1:N ê´€ê³„ë§Œ í•„ìš”

---

## 6. Frontend Routing Strategy

### Decision: TanStack Router File-based Routing

ê¸°ì¡´ í”„ë¡œì íŠ¸ì˜ TanStack Router íŒ¨í„´ì„ ìœ ì§€í•©ë‹ˆë‹¤.

### Rationale

**ê¸°ì¡´ íŒ¨í„´**:
- `src/routes/query.tsx` â†’ `/query` ê²½ë¡œ
- File-based routingìœ¼ë¡œ ê²½ë¡œì™€ íŒŒì¼ì´ 1:1 ë§¤ì¹­

**ë³€ê²½ ì‚¬í•­**:
1. `query.tsx` â†’ `retrieve.tsx` (íŒŒì¼ ì´ë¦„ ë³€ê²½)
2. `generation.tsx` ì¶”ê°€ (ìƒˆ íŒŒì¼)

**ê·¼ê±°**:
1. ì¼ê´€ì„±: ê¸°ì¡´ í”„ë¡œì íŠ¸ êµ¬ì¡° ìœ ì§€
2. ëª…ì‹œì„±: íŒŒì¼ ì´ë¦„ìœ¼ë¡œ ê²½ë¡œ ì§ê´€ì  íŒŒì•…
3. TanStack Router ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤

### Implementation Details

```typescript
// frontend/src/routes/retrieve.tsx
import { createFileRoute } from '@tanstack/react-router'

export const Route = createFileRoute('/retrieve')({
  component: RetrieveTab,
  validateSearch: (search: Record<string, unknown>) => ({
    pipelineId: search.pipelineId as number | undefined,
  }),
})

// frontend/src/routes/generation.tsx
export const Route = createFileRoute('/generation')({
  component: GenerationTab,
  validateSearch: (search: Record<string, unknown>) => ({
    pipelineId: search.pipelineId as number | undefined,
  }),
})
```

**Navigation Update**:
```typescript
// frontend/src/routes/__root.tsx
const navigation = [
  { name: 'Home', path: '/' },
  { name: 'Retrieve', path: '/retrieve' },  // Changed from 'Query'
  { name: 'Generation', path: '/generation' },  // New
  { name: 'Evaluate', path: '/evaluate' },
  ...
]
```

---

## 7. State Management for Chat UI

### Decision: Local Component State with Custom Hooks

React useState + useEffectë¡œ ì±„íŒ… ìƒíƒœë¥¼ ê´€ë¦¬í•˜ê³ , ì¬ì‚¬ìš© ê°€ëŠ¥í•œ ì»¤ìŠ¤í…€ í›…ìœ¼ë¡œ ì¶”ìƒí™”í•©ë‹ˆë‹¤.

### Rationale

**ë³µì¡ë„ í‰ê°€**:
- ì „ì—­ ìƒíƒœ í•„ìš” ì—†ìŒ: ì±„íŒ… ì„¸ì…˜ì€ Generation íƒ­ ë‚´ë¶€ì—ì„œë§Œ ì‚¬ìš©
- ì»´í¬ë„ŒíŠ¸ ê°„ ê³µìœ  ì—†ìŒ: ë‹¨ì¼ í˜ì´ì§€ ë‚´ ìƒíƒœ
- ì„œë²„ ë™ê¸°í™” ë¶ˆí•„ìš”: ì„¸ì…˜ì´ ì„œë²„ì— ì €ì¥ë˜ì§€ ì•ŠìŒ

**ê·¼ê±°**:
1. YAGNI ì›ì¹™: Redux/Zustand ë“± ë¶ˆí•„ìš”
2. React 19 ê¸°ë³¸ ê¸°ëŠ¥ìœ¼ë¡œ ì¶©ë¶„
3. í…ŒìŠ¤íŠ¸ ìš©ì´ì„±: ì»¤ìŠ¤í…€ í›… ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥

### Implementation Details

```typescript
// frontend/src/hooks/useChatSession.ts
import { useState, useCallback } from 'react';
import { v4 as uuidv4 } from 'uuid';

export interface Message {
  id: string;
  role: 'user' | 'assistant';
  content: string;
  sources?: RetrievedChunk[];
  timestamp: Date;
}

export interface ChatSession {
  id: string;
  pipelineId: number;
  modelConfig: ModelConfig;
  messages: Message[];
  createdAt: Date;
}

export function useChatSession(pipelineId: number, modelConfig: ModelConfig) {
  const [session, setSession] = useState<ChatSession>({
    id: uuidv4(),
    pipelineId,
    modelConfig,
    messages: [],
    createdAt: new Date(),
  });

  const addMessage = useCallback((message: Omit<Message, 'id' | 'timestamp'>) => {
    const newMessage: Message = {
      ...message,
      id: uuidv4(),
      timestamp: new Date(),
    };
    
    setSession(prev => ({
      ...prev,
      messages: [...prev.messages, newMessage],
    }));
  }, []);

  const clearSession = useCallback(() => {
    setSession({
      id: uuidv4(),
      pipelineId,
      modelConfig,
      messages: [],
      createdAt: new Date(),
    });
  }, [pipelineId, modelConfig]);

  return { session, addMessage, clearSession };
}
```

### Alternatives Considered

1. **Redux/Zustand (Global State)**
   - ì¥ì : ì»´í¬ë„ŒíŠ¸ ê°„ ê³µìœ  ìš©ì´
   - ë‹¨ì : ë³´ì¼ëŸ¬í”Œë ˆì´íŠ¸ ì¦ê°€, í˜„ì¬ ë¶ˆí•„ìš”
   - ê±°ë¶€ ì´ìœ : Over-engineering

2. **Context API**
   - ì¥ì : Props drilling ë°©ì§€
   - ë‹¨ì : í˜„ì¬ ì»´í¬ë„ŒíŠ¸ ê¹Šì´ê°€ ì–•ìŒ
   - ê±°ë¶€ ì´ìœ : ë³µì¡ë„ ëŒ€ë¹„ ì´ì  ì—†ìŒ

---

## Summary Table

| Decision Area | Chosen Solution | Key Rationale |
|---------------|-----------------|---------------|
| Chat Context | In-Memory (Frontend State) | ëª…ì„¸ì„œ ê°€ì •, ë‹¨ìˆœì„±, í”„ë¼ì´ë²„ì‹œ |
| Model Abstraction | Strategy Pattern | í™•ì¥ì„±, í…ŒìŠ¤íŠ¸ ìš©ì´ì„±, ì¼ê´€ì„± |
| Prompt Template | System + Context + User | Hallucination ê°ì†Œ, ì¶œì²˜ ëª…ì‹œ |
| Error Handling | Exponential Backoff + Circuit Breaker | ê°€ìš©ì„±, ì‚¬ìš©ì ê²½í—˜ |
| Dataset Filtering | Existing FK Relationship | ì´ë¯¸ êµ¬í˜„ë¨, ë‹¨ìˆœì„± |
| Frontend Routing | TanStack File-based | ê¸°ì¡´ íŒ¨í„´ ìœ ì§€, ì¼ê´€ì„± |
| Chat State | Local State + Custom Hooks | YAGNI, ë‹¨ìˆœì„±, í…ŒìŠ¤íŠ¸ ìš©ì´ì„± |

## Next Steps

1. âœ… Research completed
2. ğŸ”„ Create data-model.md with entity definitions
3. ğŸ”„ Create API contracts (OpenAPI specs)
4. ğŸ”„ Create quickstart.md for developers
5. â³ Begin Phase 2 implementation

