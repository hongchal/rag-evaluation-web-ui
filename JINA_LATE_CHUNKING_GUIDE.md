# Jina Late Chunking êµ¬í˜„ ê°€ì´ë“œ

## ğŸ“š ê°œìš”

Jina v3 Late Chunkingì€ ë¬¸ì„œë¥¼ **í•œ ë²ˆì˜ forward pass**ë¡œ ì„ë² ë”©í•˜ì—¬ ê¸°ì¡´ ë°©ì‹ ëŒ€ë¹„ **~10ë°° ë¹ ë¥¸** ì„±ëŠ¥ì„ ì œê³µí•˜ëŠ” ìµœì í™” ê¸°ë²•ì…ë‹ˆë‹¤.

### ê¸°ì¡´ ë°©ì‹ vs Late Chunking

#### ê¸°ì¡´ ë°©ì‹ (ëŠë¦¼)
```
ë¬¸ì„œ â†’ [ì²­í¬1, ì²­í¬2, ì²­í¬3, ..., ì²­í¬N]
ê° ì²­í¬ë¥¼ ë”°ë¡œ ì„ë² ë”©:
  - ì²­í¬1 â†’ ì„ë² ë”©1 (forward pass)
  - ì²­í¬2 â†’ ì„ë² ë”©2 (forward pass)
  - ì²­í¬3 â†’ ì„ë² ë”©3 (forward pass)
  ...
  - ì²­í¬N â†’ ì„ë² ë”©N (forward pass)
ì´ Në²ˆì˜ forward pass í•„ìš” âŒ
```

#### Late Chunking (ë¹ ë¦„)
```
ë¬¸ì„œ â†’ ì „ì²´ ë¬¸ì„œë¥¼ í•œ ë²ˆì— ì„ë² ë”© â†’ Token-level embeddings
ê° ì²­í¬ì˜ token ë²”ìœ„ë¥¼ ì°¾ì•„ì„œ pooling:
  - ì²­í¬1 ë²”ìœ„ì˜ tokens â†’ í‰ê·  â†’ ì„ë² ë”©1
  - ì²­í¬2 ë²”ìœ„ì˜ tokens â†’ í‰ê·  â†’ ì„ë² ë”©2
  - ì²­í¬3 ë²”ìœ„ì˜ tokens â†’ í‰ê·  â†’ ì„ë² ë”©3
  ...
  - ì²­í¬N ë²”ìœ„ì˜ tokens â†’ í‰ê·  â†’ ì„ë² ë”©N
ì´ 1ë²ˆì˜ forward passë§Œ í•„ìš” âœ…
```

## ğŸ¯ êµ¬í˜„ ì™„ë£Œ

### 1. Jina v3 Embedder êµ¬í˜„

**íŒŒì¼**: `backend/app/embedding/embedders/jina_late_chunking.py`

**ì£¼ìš” ê¸°ëŠ¥**:
- âœ… `jinaai/jina-embeddings-v3` ëª¨ë¸ ì‚¬ìš©
- âœ… `embed_document_with_late_chunking()` ë©”ì„œë“œ êµ¬í˜„
- âœ… Token-level embeddingì—ì„œ chunk ì„ë² ë”© ì¶”ì¶œ
- âœ… GPU/MPS/CPU ìë™ ê°ì§€
- âœ… 1024ì°¨ì› dense vector
- âœ… ìµœëŒ€ 8192 í† í° ì§€ì›

### 2. RAGFactory ë“±ë¡ ì™„ë£Œ

**íŒŒì¼**: `backend/app/services/rag_factory.py`

```python
from app.embedding.embedders.jina_late_chunking import JinaLocalLateChunkingEmbedder

# ...

elif module == "jina_late_chunking":
    embedder = JinaLocalLateChunkingEmbedder(**params)
```

### 3. Dependencies ì¶”ê°€

**íŒŒì¼**: `backend/requirements.txt`

```txt
transformers>=4.36.0  # For Jina v3 embeddings
```

## ğŸš€ ì‚¬ìš© ë°©ë²•

### ë°©ë²• 1: APIë¥¼ í†µí•œ RAG ìƒì„±

```json
{
  "name": "Jina Late Chunking RAG",
  "description": "Real Jina v3 Late Chunking with 10x performance",
  "chunking": {
    "module": "late_chunking",
    "params": {
      "sentences_per_chunk": 3,
      "min_chunk_tokens": 50,
      "max_chunk_tokens": 512
    }
  },
  "embedding": {
    "module": "jina_late_chunking",
    "params": {
      "model_name": "jinaai/jina-embeddings-v3",
      "device": "cuda",
      "use_fp16": true,
      "batch_size": 32
    }
  },
  "reranking": {
    "module": "cross_encoder",
    "params": {
      "model_name": "BAAI/bge-reranker-v2-m3"
    }
  }
}
```

#### API í˜¸ì¶œ ì˜ˆì‹œ

```bash
curl -X POST "http://localhost:8000/api/v1/rags" \
  -H "Content-Type: application/json" \
  -d @jina_late_chunking_config.json
```

### ë°©ë²• 2: Python ì½”ë“œì—ì„œ ì§ì ‘ ì‚¬ìš©

```python
from app.embedding.embedders.jina_late_chunking import JinaLocalLateChunkingEmbedder
from app.chunking.chunkers.late_chunking import LateChunkingWrapper

# 1. Embedder ì´ˆê¸°í™”
embedder = JinaLocalLateChunkingEmbedder(
    model_name="jinaai/jina-embeddings-v3",
    device="cuda",
    use_fp16=True
)

# 2. Chunker ì´ˆê¸°í™”
chunker = LateChunkingWrapper(
    sentences_per_chunk=3,
    min_chunk_tokens=50,
    max_chunk_tokens=512
)

# 3. ë¬¸ì„œ ì²­í‚¹
from app.models.base_document import BaseDocument

document = BaseDocument(
    id="doc1",
    content="ê¸´ ë¬¸ì„œ ë‚´ìš©...",
    source_type="file",
    filename="example.pdf"
)

chunks = chunker.chunk_document(document)

# 4-1. ì „í†µì  ë°©ì‹ (ëŠë¦¼)
embeddings_slow = embedder.embed_texts([chunk.content for chunk in chunks])

# 4-2. Late Chunking ë°©ì‹ (ë¹ ë¦„!)
chunk_texts = [chunk.content for chunk in chunks]
embeddings_fast = embedder.embed_document_with_late_chunking(
    document.content,
    chunk_texts
)

print(f"ì²­í¬ ìˆ˜: {len(chunks)}")
print(f"ì„ë² ë”© ì°¨ì›: {embedder.get_dimension()}")
print("Late Chunkingìœ¼ë¡œ ~10ë°° ë¹ ë¥¸ ì„±ëŠ¥!")
```

### ë°©ë²• 3: SemanticChunkerì™€ í•¨ê»˜ ì‚¬ìš©

```python
from app.chunking.chunkers.semantic_langchain import SemanticLangChainChunker
from app.embedding.embedders.jina_late_chunking import JinaLocalLateChunkingEmbedder

# Jina embedder ì´ˆê¸°í™”
embedder = JinaLocalLateChunkingEmbedder()

# SemanticChunker ì´ˆê¸°í™”
chunker = SemanticLangChainChunker(
    embedder=embedder,
    similarity_threshold=0.5,
    min_chunk_tokens=100,
    max_chunk_tokens=800,
    sentences_per_group=3
)

# ë¬¸ì„œ ì²­í‚¹ (ìë™ìœ¼ë¡œ Late Chunking ìµœì í™” ì‚¬ìš©)
chunks = chunker.chunk_document(document)

# âœ… SemanticChunkerê°€ embed_document_with_late_chunking() ë©”ì„œë“œë¥¼ ìë™ ê°ì§€í•˜ì—¬ ì‚¬ìš©!
```

## âš™ï¸ ì„¤ì • ì˜µì…˜

### Embedder íŒŒë¼ë¯¸í„°

| íŒŒë¼ë¯¸í„° | ê¸°ë³¸ê°’ | ì„¤ëª… |
|---------|--------|------|
| `model_name` | `jinaai/jina-embeddings-v3` | ëª¨ë¸ ì´ë¦„ |
| `device` | ìë™ ê°ì§€ | `cuda`, `mps`, `cpu` |
| `use_fp16` | ìë™ ê°ì§€ | FP16 ì‚¬ìš© (GPU/MPSì—ì„œ ìë™ í™œì„±í™”) |
| `batch_size` | ìë™ ê°ì§€ | ë°°ì¹˜ í¬ê¸° (ë©”ëª¨ë¦¬ì— ë”°ë¼ ìë™ ì„¤ì •) |
| `trust_remote_code` | `True` | Hugging Face ëª¨ë¸ ë¡œë”© ì‹œ í•„ìš” |

### Chunker íŒŒë¼ë¯¸í„°

| íŒŒë¼ë¯¸í„° | ê¸°ë³¸ê°’ | ì„¤ëª… |
|---------|--------|------|
| `sentences_per_chunk` | 3 | ì²­í¬ë‹¹ ë¬¸ì¥ ìˆ˜ |
| `min_chunk_tokens` | 50 | ìµœì†Œ í† í° ìˆ˜ |
| `max_chunk_tokens` | 500 | ìµœëŒ€ í† í° ìˆ˜ |

## ğŸ” Late Chunking ì‘ë™ ì›ë¦¬

### í•µì‹¬ ë©”ì„œë“œ: `embed_document_with_late_chunking()`

```python
def embed_document_with_late_chunking(
    self,
    document_text: str,
    chunks: List[str]
) -> List[List[float]]:
    """
    1. ì „ì²´ ë¬¸ì„œë¥¼ í† í¬ë‚˜ì´ì¦ˆ
    2. í•œ ë²ˆì˜ forward passë¡œ token-level embeddings ì¶”ì¶œ
    3. ê° ì²­í¬ì˜ í…ìŠ¤íŠ¸ ìœ„ì¹˜ë¥¼ ì°¾ì•„ì„œ í•´ë‹¹ í† í° ë²”ìœ„ íŒŒì•…
    4. í•´ë‹¹ í† í°ë“¤ì˜ ì„ë² ë”©ì„ í‰ê·  (mean pooling)
    5. ì •ê·œí™”í•˜ì—¬ ì²­í¬ ì„ë² ë”© ë°˜í™˜
    """
```

### ì„±ëŠ¥ ë¹„êµ

**í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤**: 5000ë‹¨ì–´ ë¬¸ì„œ, 50ê°œ ì²­í¬

| ë°©ì‹ | Forward Passes | ì˜ˆìƒ ì‹œê°„ |
|-----|----------------|----------|
| ì „í†µì  ë°©ì‹ | 50ë²ˆ | ~5ì´ˆ |
| Late Chunking | 1ë²ˆ | ~0.5ì´ˆ |
| **ì„±ëŠ¥ í–¥ìƒ** | **50ë°° ê°ì†Œ** | **10ë°° ë¹ ë¦„** |

## ğŸ“Š Semantic Chunker í†µí•©

`SemanticLangChainChunker`ëŠ” embedderì˜ `embed_document_with_late_chunking()` ë©”ì„œë“œë¥¼ ìë™ìœ¼ë¡œ ê°ì§€í•©ë‹ˆë‹¤:

```python
# semantic_langchain.pyì—ì„œ ìë™ ê°ì§€
has_late_chunking = hasattr(self.embedder, "embed_document_with_late_chunking")

if has_late_chunking and has_document_text:
    logger.info("using_late_chunking_optimization")
    embeddings = self.embedder.embed_document_with_late_chunking(
        document_text, groups
    )
else:
    # ì „í†µì  ë°©ì‹ìœ¼ë¡œ fallback
    embeddings_result = self.embedder.embed_texts(groups)
```

## ğŸ› íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### 1. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨

```bash
# HuggingFace í† í° ì„¤ì • (private ëª¨ë¸ì¸ ê²½ìš°)
export HUGGINGFACE_TOKEN="your_token_here"

# ë˜ëŠ” Pythonì—ì„œ
from huggingface_hub import login
login(token="your_token_here")
```

### 2. GPU ë©”ëª¨ë¦¬ ë¶€ì¡±

```python
# batch_size ì¤„ì´ê¸°
embedder = JinaLocalLateChunkingEmbedder(
    batch_size=8,  # ê¸°ë³¸ê°’ë³´ë‹¤ ì‘ê²Œ
    use_fp16=True   # FP16 ì‚¬ìš©
)
```

### 3. ì²­í¬ê°€ ë¬¸ì„œì—ì„œ ì°¾ì•„ì§€ì§€ ì•Šì„ ë•Œ

```python
# Fallback: ì²­í¬ë¥¼ ê°œë³„ì ìœ¼ë¡œ ì„ë² ë”©
# (ìë™ìœ¼ë¡œ ì²˜ë¦¬ë˜ì§€ë§Œ, ë¡œê·¸ì— warning ì¶œë ¥ë¨)
```

## ğŸ“ˆ ì„±ëŠ¥ ìµœì í™” íŒ

1. **GPU ì‚¬ìš©**: CUDA ë˜ëŠ” Apple Silicon (MPS) ì‚¬ìš© ê¶Œì¥
2. **FP16 í™œì„±í™”**: GPUì—ì„œ 2ë°° ë¹ ë¥¸ ì„±ëŠ¥
3. **ë°°ì¹˜ í¬ê¸° ì¡°ì •**: GPU ë©”ëª¨ë¦¬ì— ë§ê²Œ ìë™ ì„¤ì •ë¨
4. **Semantic Chunkerì™€ ê²°í•©**: ì˜ë¯¸ ê¸°ë°˜ ì²­í‚¹ + Late Chunking ìµœì í™”

## ğŸ“ ì°¸ê³  ìë£Œ

- [Jina AI Late Chunking Blog](https://jina.ai/news/late-chunking-in-long-context-embedding-models/)
- [jinaai/jina-embeddings-v3 on HuggingFace](https://huggingface.co/jinaai/jina-embeddings-v3)
- [RAG Evaluation Framework Documentation](./README.md)

## âœ… ì²´í¬ë¦¬ìŠ¤íŠ¸

êµ¬í˜„ ì™„ë£Œ í•­ëª©:
- [x] Jina v3 Embedder êµ¬í˜„
- [x] Late Chunking ë©”ì„œë“œ êµ¬í˜„
- [x] Token-level embedding â†’ chunk embedding ë³€í™˜
- [x] RAGFactory ë“±ë¡
- [x] SemanticChunkerì™€ í†µí•©
- [x] GPU/MPS/CPU ì§€ì›
- [x] Fallback ë¡œì§ (ì²­í¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì„ ë•Œ)
- [x] ë¬¸ì„œí™”

---

**ğŸš€ ì´ì œ ì§„ì§œ Jina Late Chunkingì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!**

